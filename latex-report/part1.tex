\section{Graded Assignment 1}\label{sec:graded_assignment_1}
The IMM-PDAF combines Interactive Multiple Models (IMM) with Probabilistic Data Association Filter (PDAF). Relevant theory can be found in \cite[p. 100-101, 120 - 122]{Edmund}. 

\subsection*{Results}
\subsubsection*{Simulated dataset}
Tuning the full system for the simulated data required tuning of, in total, four systems. These were the Extended Kalman Filters, for the Constant Velocity and Constant Turn-rate modes, the IMM, and the IMM-PDAF. 

For the CV-model, the measurement noise covariance parameter used was $4$, while the acceleration noise covariance parameter used was $\scinot{8}{-2}$. Similarly, the same measurement noise covariance parameter was used for the CT-model, as the measurement noises should be similar. Furthermore, the acceleration noise covariance parameter used was $5e-3$ and the turn-rate noise parameter used was $3e-4$. Tuning these parameters would have some impact on the consistency, higher noise would lower the NEES, while lower noise increases the NEES, which is to be expected as we are essentially changing how much the filter should trust the measurements contra the estimates. 

The IMM was tuned using the transition matrix $\pi$, which was tuned as \cref{eq:ga_1_2_pi_matrix}. With the CV-model as the first model and the CT-model as the second, the argument is that if the IMM is in a given mode, it should most likely stay. Still, it may be beneficial to be more likely to change to, and stay as, the CT-model. When observing the trajectory, see \cref{fig:ga_1_2_estimated_trajectory}, it seems to primarily use the CV-model, and then increasing the transition probability for changing to the CT-model would speed up this transition. 

\begin{equation}
    \label{eq:ga_1_2_pi_matrix}
    \pi = \begin{bmatrix}
        0.92 & 0.05 \\
        0.08 & 0.95
    \end{bmatrix}
\end{equation}

Finally, for the IMM-PDAF, the clutter rate $\lambda$, detection probability $P_D$ and the validation gate were tuned. The clutter rate was tuned to $\lambda = \scinot{1}{-4}$, and as there were very few false alarms, this could be chosen as a low value. Furthermore, as the only place the clutter rate is used in the IMM-PDAF is to scale the probability of no detection, there was really no use further decreasing $\lambda$, as it already would put the association likelihood ratio for no detection very low. The detection probability is tuned to be rather high, with $P_D = 0.95$, as it is expected that there is a good chance of detection for this dataset. A validation gate size of $5^2$ seemed also to give decent results. Increasing it would generally not make the tracker worse overall, but would increase the magnitude of certain errors, which would then spike. Decreasing it would of course make it more difficult for any measurements to be gated, such that this value seemed to be the best compromise between gating all and no measurements. 

\subsubsection*{Joyride dataset}
Initially, the IMM-PDAF for the Joyride dataset was tuned similarly to the tracker for the simulated dataset, and especially for the low noise CV model and the CT model, similar values were used. Furthermore, it should be noted that the Joyride dataset also was noisier, such that more lenient tuning was necessary. For this dataset, a high noise CV model was also included, which could \textit{take over} if both the low noise CV model and the CT model were uncertain. Otherwise, the overall structure of the tracker is the same as for the simulated dataset. 

The measurement noise covariance parameter was again the same for the CT and two CV models, and was set to $25^2$. Though this seemed rather higher than necessary, however lowering it would especially push higher the positional NEES. Similar responses were generated from tuning the acceleration noise covariance parameters and turn-rate noise covariance parameter for the different models. Then, for the low noise CV model, the acceleration noise covariance parameter was tuned to $0.5$, for the high noise CV model, the acceleration noise covariance parameter was tuned to $20$ and for the CT model, the acceleration noise covariance parameter was tuned to $\scinot{1}{-4}$ and the turn-rate noise covariance parameter was tuned to $\scinot{2}{-4}$. 

As for the IMM used in the simulated dataset, the transition matrix $\pi$ was tuned to prefer to stay in the CT-mode, so that the tracker should prefer to continue a turn if it has begun. Since the high noise CV model was included primarily to handle high noise areas where it could be unambiguous whether to use the low noise CV or CT model, this transition probability was set lower than the others, as those should be preferred. From observing the track and measurements, there also seemed to be unambiguous which of the other modes each should transition to, and as such these transitions were set to be equally likely, see \cref{eq:ga_1_joyride_pi_matrix}. 

\begin{equation}
    \label{eq:ga_1_joyride_pi_matrix}
    \pi = \begin{bmatrix}
        0.900 & 0.025 & 0.075 \\
        0.050 & 0.950 & 0.075 \\
        0.050 & 0.025 & 0.850 
    \end{bmatrix}
\end{equation}

The IMM-PDAF was tuned to have a lower clutter rate and higher detection probability than for the simulated data, while keeping the gate size. The clutter rate was tuned to be $\lambda = \scinot{5}{-5}$. Higher values would inevitably make the tracker loose track and converge to one mode, rendering the tracker useless. As the clutter rate affects the likelihood ratio for no detection, a higher clutter rate implies a higher likelihood compared to a lower clutter rate, and a higher value would be given to the association probability for no detection. The detection probability was tuned to $P_D = 0.97$, which is a rather high value. It was possible to reduce $P_D$ and, specifically, improve the percentage where the NEES is inside CI, but at a cost of the NEES for the velocity, and a higher $P_D$ was chosen so that the NEESes would be more similar. 

% note that q lower for CT? 

% parameters 

% In the report you should do a bit more analysis of what happens with different parameters settings, and base your choice on relevant plots and numbers. To achieve a full score we also want to see at least some minor reflections on the algorithm and the approximations it does in light of your results. 
% We want to see an analysis of what happens and why with some different parameter/model settings, and base your choice of model and parameters on relevant plots and numbers. To achieve a full score we also want to see at least some minor reflections on the algorithm and the approximations it does, in light of your results. Relating results in this tasks or assignments to the previous task can give additional points. 

\begin{figure}[ht]
	\begin{subfigure}[h]{0.4\textwidth}
		\includegraphics[width=\textwidth]{figures/ga_1/2_NEES}
		\caption{NEES for simulated data}
		\label{fig:ga_1_2_NEES}
    \end{subfigure}%
    ~
	\begin{subfigure}[h]{0.4\textwidth}
		\includegraphics[width=\textwidth]{figures/ga_1/joyride_NEES}
		\caption{NEES for Joyride}
		\label{fig:ga_1_joyride_NEES}
	\end{subfigure}
        \\
    \begin{subfigure}[h]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/ga_1/2_estimated_trajectory}
        \caption{Trajectory for simulated data}
        \label{fig:ga_1_2_estimated_trajectory}
    \end{subfigure}%
    ~
    \begin{subfigure}[h]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/ga_1/joyride_estimated_trajectory}
        \caption{Trajectory for Joyride}
        \label{fig:ga_1_joyride_estimated_trajectory}
    \end{subfigure}
        \\
    \begin{subfigure}[h]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/ga_1/2_error}
        \caption{Errors for simulated data}
        \label{fig:ga_1_2_error}
    \end{subfigure}%
    ~
    \begin{subfigure}[h]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/ga_1/joyride_error}
        \caption{Errors for Joyride}
        \label{fig:ga_1_joyride_error}
    \end{subfigure}
        \\
    \begin{subfigure}[h]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/ga_1/2_probs}
        \caption{Probabilities simulated data}
        \label{fig:ga_1_2_error}
    \end{subfigure}%
    ~
    \begin{subfigure}[h]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/ga_1/joyride_probs}
        \caption{Probabilities for Joyride}
        \label{fig:ga_1_joyride_error}
    \end{subfigure}
    \caption{The same colour code was utilised for visualising the active modes in the trajectories as the probabilities. For the trajectories, ground truth is represented as a dashed line. }
    \label{fig:ga_1} 
\end{figure}

% task 2 and 3
    % NEES with confidence bounds
        % total
        % position
        % velocity
    % estimation error (Euclidian distance)
        % position 
        % velocity
    % averaged NEESes 
    % number of times the NEESes fall within the confidence region
    % position and velocity RMSE (mean taken over time)

% parameters based on this
% other plots




% For task 2 and 3, we want to see a plot of the total, position and velocity NEES along with your chosen confidence bounds for these, and estimation error (Euclidian distance) in position and velocity for the tracker run with your chosen parameters. 
% In addition we want the numbers of the averaged NEESes along with their confidence bounds, the number of times the NEESes fall within the confidence regions and the positional and velocity RMSE (mean taken over time). 
% We then expect you to base your choice of parameters on these values, and compare to other sets of parameters. 
% To show plots of other parameter settings is up to you. 